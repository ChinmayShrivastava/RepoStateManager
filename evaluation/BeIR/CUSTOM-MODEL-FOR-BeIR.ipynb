{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict\n",
    "\n",
    "class BaseSearch(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def search(self, \n",
    "               queries: Dict[str, str], \n",
    "               top_k: int, \n",
    "               **kwargs) -> Dict[str, Dict[str, float]]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# move two directories up and make that current directory\n",
    "os.chdir(\"../..\")\n",
    "# print current directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def cos_sim(a: torch.Tensor, b: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1)) #TODO: this keeps allocating GPU memory\n",
    "\n",
    "def dot_score(a: torch.Tensor, b: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Computes the dot-product dot_prod(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = dot_prod(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    return torch.mm(a, b.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVectorGraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorGraph\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "from modules.vectorgraph.VectorGraph import VectorGraph\n",
    "from typing import Dict\n",
    "import tqdm\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class VectorGraphRetrieval(BaseSearch):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        persisting_dir: str,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.vg = VectorGraph.from_persisting_dir(\n",
    "            persisting_dir=persisting_dir,\n",
    "            verbose=False\n",
    "        )\n",
    "        self.verbose = kwargs.get(\"verbose\", True)\n",
    "        self.results = {}\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str], \n",
    "        top_k: int,\n",
    "        **kwargs\n",
    "    ) -> Dict[str, Dict[str, float]]:\n",
    "            \n",
    "        logger.info(\"Loading Queries...\")\n",
    "        query_ids = list(queries.keys())\n",
    "        self.results = {qid: {} for qid in query_ids}\n",
    "        queries = [queries[qid] for qid in queries]\n",
    "\n",
    "        logger.info(\"Retrieving...\")\n",
    "        #  use tqdm if verbose is True\n",
    "        if self.verbose:\n",
    "            for qid, query in tqdm.tqdm(zip(query_ids, queries), total=len(queries)):\n",
    "                _res = self.vg.query_with_chunk_ids(\n",
    "                    query=query,\n",
    "                    top_k=top_k\n",
    "                )\n",
    "                for _res_item in _res:\n",
    "                    self.results[qid][_res_item[0]] = 1\n",
    "        else:\n",
    "            for qid, query in zip(query_ids, queries):\n",
    "                _res = self.vg.query_with_chunk_ids(\n",
    "                    query=query,\n",
    "                    top_k=top_k\n",
    "                )\n",
    "                for _res_item in _res:\n",
    "                    self.results[qid][_res_item[0]] = 1\n",
    "\n",
    "        logger.info(\"Done!\")\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
