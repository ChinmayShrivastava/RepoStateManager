{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 16207 nodes and 36362 edges\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "repo_id = '45526e5b-f544-4016-8381-f88f5ca095ea'\n",
    "G = pickle.load(open(repo_id+'/state_0.pkl', 'rb'))\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Superagent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSuperagent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/RepoStateManager/venv/lib/python3.11/site-packages/networkx/classes/reportviews.py:360\u001b[0m, in \u001b[0;36mNodeDataView.__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNetworkXError(\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support slicing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtry list(G.nodes.data())[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;241m.\u001b[39mstop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m     )\n\u001b[0;32m--> 360\u001b[0m ddict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    361\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Superagent'"
     ]
    }
   ],
   "source": [
    "G.nodes(data=True)['Superagent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n",
      "SimpleMongoReader\n",
      "RocksetVectorStore\n",
      "SQLJoinQueryEngine\n",
      "BaseStructStoreIndex\n",
      "SentenceSplitter\n",
      "TreeSummarize\n",
      "IPYNBReader\n",
      "AzureOpenAIEmbedding\n",
      "Perplexity\n",
      "CassandraVectorStore\n",
      "LlamaCPP\n",
      "FaissVectorStore\n",
      "LangchainPromptTemplate\n",
      "LLMMultiSelector\n",
      "BagelVectorStore\n",
      "AimCallback\n",
      "DFFullProgram\n",
      "OpenAIQuestionGenerator\n",
      "CondenseQuestionChatEngine\n",
      "DocumentSummaryIndex\n",
      "GoogleVectorStore\n",
      "FaissReader\n",
      "MockChatLLM\n",
      "OpenLLM\n",
      "ZepVectorStore\n",
      "LinearLayer\n",
      "Accumulate\n",
      "EvaporateExtractor\n",
      "CondensePlusContextChatEngine\n",
      "PaLM\n",
      "PGVectoRsStore\n",
      "NLStructStoreQueryEngine\n",
      "ElasticsearchReader\n",
      "SlackReader\n",
      "OpenAIEmbedding\n",
      "ReActAgent\n",
      "MongoDocumentStore\n",
      "OpenAI\n",
      "Neo4jGraphStore\n",
      "Anthropic\n",
      "MetaProvider\n",
      "MultiModalVectorIndexRetriever\n",
      "Refine\n",
      "AwadbReader\n",
      "GradientBaseModelLLM\n",
      "GradientFinetuneEngine\n",
      "VectorStoreIndex\n",
      "OpenAIFinetuneEngine\n",
      "LangchainEmbedding\n",
      "SQLDatabase\n",
      "FirestoreKVStore\n",
      "SummaryExtractor\n",
      "LLMPredictor\n",
      "OnDemandLoaderTool\n",
      "WatsonX\n",
      "PandasIndex\n",
      "MetalVectorStore\n",
      "PGVectorSQLParser\n",
      "DocArrayInMemoryVectorStore\n",
      "DiscordReader\n",
      "TokenCountingHandler\n",
      "UnstructuredElementNodeParser\n",
      "S3DBKVStore\n",
      "PDFReader\n",
      "BufferedGitBlobDataIterator\n",
      "QdrantReader\n",
      "ReplicateMultiModal\n",
      "OpensearchVectorStore\n",
      "MultiModalRetrieverEvaluator\n",
      "SummaryIndexRetriever\n",
      "SimpleSummarize\n",
      "MockObject2\n",
      "ColbertIndex\n",
      "FakeGoogleDataclass\n",
      "ElasticsearchStore\n",
      "SQLStructDatapointExtractor\n",
      "TreeSelectLeafRetriever\n",
      "TwoLayerNN\n",
      "LLMLookaheadAnswerInserter\n",
      "MockForkStepEngine\n",
      "MockIBMModelModule\n",
      "BarkTTS\n",
      "DatasetGenerator\n",
      "SentenceTransformersFinetuneEngine\n",
      "ZillizCloudPipelineRetriever\n",
      "HuggingFaceLLM\n",
      "DynamoDBDocumentStore\n",
      "RssReader\n",
      "AnthropicProvider\n",
      "TransformRetriever\n",
      "TitleExtractor\n",
      "MilvusVectorStore\n",
      "SQLTableNodeMapping\n",
      "BaseOpenAIAgent\n",
      "MboxReader\n",
      "_BaseGradientLLM\n",
      "MultiModalRelevancyEvaluator\n",
      "EpsillaVectorStore\n",
      "FeedbackQueryTransformation\n",
      "MyScaleReader\n",
      "RedisDocumentStore\n",
      "AsyncParamTuner\n",
      "TypesenseVectorStore\n",
      "GuidanceQuestionGenerator\n",
      "MockMongoCollection\n",
      "MyScaleVectorStore\n",
      "ContextChatEngine\n",
      "FunctionTool\n",
      "ObjectIndex\n",
      "SimpleKVStore\n",
      "ChatPromptTemplate\n",
      "KuzuGraphStore\n",
      "MonsterLLM\n",
      "RetrieverTool\n",
      "PsychicReader\n",
      "JSONReader\n",
      "DocArrayHnswVectorStore\n",
      "PromptHelper\n",
      "MetalReader\n",
      "BeirEvaluator\n",
      "Vertex\n",
      "SimpleVectorStore\n",
      "ClarifaiEmbedding\n",
      "TestLLM\n",
      "SummaryIndexEmbeddingRetriever\n",
      "BeautifulSoupWebReader\n",
      "SimpleObjectNodeMapping\n",
      "SQLDocumentContextBuilder\n",
      "BaseIndex\n",
      "MultiModalLLMCompletionProgram\n",
      "BaseFinetuningHandler\n",
      "CognitiveSearchVectorStore\n",
      "PairwiseComparisonEvaluator\n",
      "BaseSynthesizer\n",
      "HTMLTagReader\n",
      "GlobalsHelper\n",
      "SQLStructStoreIndex\n",
      "MockOutputParser\n",
      "VectorIndexAutoRetriever\n",
      "Xinference\n",
      "BaseEvaporateProgram\n",
      "PptxReader\n",
      "MyScaleSettings\n",
      "FirestoreIndexStore\n",
      "LlamaLogger\n",
      "FlagEmbeddingReranker\n",
      "DynamoDBVectorStore\n",
      "LongLLMLinguaPostprocessor\n",
      "QueryFusionRetriever\n",
      "TokenCounter\n",
      "DFRowsProgram\n",
      "EmbeddingSingleSelector\n",
      "NoSuchCorpusException\n",
      "TreeIndexInserter\n",
      "CrossEncoderFinetuneEngine\n",
      "MockEvaluator\n",
      "LlamaDebugHandler\n",
      "TreeIndex\n",
      "HuggingFaceEmbedding\n",
      "MilvusReader\n",
      "GeminiEmbedding\n",
      "SQLAutoVectorQueryEngine\n",
      "LangChainLLM\n",
      "QASummaryQueryEngineBuilder\n",
      "KnowledgeGraphQueryEngine\n",
      "GradientEmbedding\n",
      "ReActAgentWorker\n",
      "RetryQueryEngine\n",
      "BaseTTS\n",
      "HotpotQARetriever\n",
      "MockEmbedding\n",
      "VellumPromptRegistry\n",
      "SimpleIndexStore\n",
      "MistralAI\n",
      "DocumentSummaryIndexEmbeddingRetriever\n",
      "DeepLakeVectorStore\n",
      "KVDocumentStore\n",
      "PandasCSVReader\n",
      "KnowledgeGraphIndex\n",
      "GuidelineEvaluator\n",
      "RetryGuidelineQueryEngine\n",
      "TimescaleVectorStore\n",
      "AwaDBVectorStore\n",
      "DatabaseReader\n",
      "TokenEscaper\n",
      "SubQuestionQueryEngine\n",
      "FLAREInstructQueryEngine\n",
      "ImageVisionLLMReader\n",
      "Portkey\n",
      "TwitterTweetReader\n",
      "ClipEmbedding\n",
      "NotionPageReader\n",
      "OpenAIPydanticProgram\n",
      "SimpleDirectoryReader\n",
      "ObsidianReader\n",
      "BaseRetriever\n",
      "CollectionParams\n",
      "YouRetriever\n",
      "RecursiveRetriever\n",
      "TrafilaturaWebReader\n",
      "IsDoneOutputParser\n",
      "AstraDBVectorStore\n",
      "OpenAIAgent\n",
      "EmptyIndex\n",
      "RouterQueryEngine\n",
      "EventContext\n",
      "SteamshipFileReader\n",
      "MultiModalFaithfulnessEvaluator\n",
      "TreeRootRetriever\n",
      "Clarifai\n",
      "LangchainOutputParser\n",
      "FalkorDBGraphStore\n",
      "LlamaAPI\n",
      "VectaraIndex\n",
      "MultiModalVectorStoreIndex\n",
      "ImageReader\n",
      "GeminiMultiModal\n",
      "ImageCaptionReader\n",
      "FilterField\n",
      "BagelReader\n",
      "Cohere\n",
      "RetrieverRouterQueryEngine\n",
      "SentenceTransformerRerank\n",
      "MongoIndexStore\n",
      "PydanticMultiSelector\n",
      "MyMultipleNegativesRankingLoss\n",
      "AI21\n",
      "GoogleUnivSentEncoderEmbedding\n",
      "SimpleLLMHandler\n",
      "GoogleSheetsReader\n",
      "RagDatasetGenerator\n",
      "ChromaReader\n",
      "OpenRouter\n",
      "AutoMergingRetriever\n",
      "CohereEmbedding\n",
      "PydanticSingleSelector\n",
      "LLMRerank\n",
      "MultiStepQueryEngine\n",
      "PromptTemplate\n",
      "LLMQuestionGenerator\n",
      "ChatGPTRetrievalPluginReader\n",
      "ConditionalException\n",
      "HWPReader\n",
      "InstructorEmbedding\n",
      "VectaraQueryEngine\n",
      "SingleStoreVectorStore\n",
      "NotionToolSpec\n",
      "EntityExtractor\n",
      "SimpleDocumentStore\n",
      "RedisKVStore\n",
      "Bedrock\n",
      "TairVectorStore\n",
      "HyDEQueryTransform\n",
      "VoyageEmbedding\n",
      "MockMongoClient\n",
      "PandasQueryEngine\n",
      "SlackToolSpec\n",
      "SelectorPromptTemplate\n",
      "ImageOutputQueryTransform\n",
      "SimpleWebPageReader\n",
      "DashVectorStore\n",
      "GooglePaLMEmbedding\n",
      "SQLContextContainerBuilder\n",
      "DefaultRefineProgram\n",
      "AzureOpenAI\n",
      "RedisVectorStore\n",
      "TestSQLDatabase\n",
      "BufferedAsyncIterator\n",
      "PGVectorStore\n",
      "MockStreamCompletionWithRetry\n",
      "BedrockEmbedding\n",
      "OptimumEmbedding\n",
      "TokenTextSplitter\n",
      "Playground\n",
      "OpenLLMAPI\n",
      "PredibaseLLM\n",
      "MockPineconeIndex\n",
      "ComposableGraphQueryEngine\n",
      "StepDecomposeQueryTransform\n",
      "RunGptLLM\n",
      "GoogleDocsReader\n",
      "BaseKeywordTableRetriever\n",
      "SupabaseVectorStore\n",
      "MockAgentWorker\n",
      "QueryPlanTool\n",
      "SummaryIndex\n",
      "LocalAI\n",
      "BaseCallbackHandler\n",
      "MetadataReplacementPostProcessor\n",
      "MockObject1\n",
      "OpenInferenceCallbackHandler\n",
      "BaseQueryEngine\n",
      "ColbertRetriever\n",
      "SQLRetriever\n",
      "MarkdownReader\n",
      "BaseManagedIndex\n",
      "SimpleToolNodeMapping\n",
      "LoadAndSearchToolSpec\n",
      "Anyscale\n",
      "TransformQueryEngine\n",
      "CorrectnessEvaluator\n",
      "DynamoDBKVStore\n",
      "LLMSingleSelector\n",
      "BaseToolAsyncAdapter\n",
      "VllmServer\n",
      "PydanticOutputParser\n",
      "VectaraRetriever\n",
      "AgentRunner\n",
      "ZillizCloudPipelineIndex\n",
      "ParallelAgentRunner\n",
      "GithubClient\n",
      "ElasticsearchEmbedding\n",
      "Gemini\n",
      "SimpleGraphStore\n",
      "Phone\n",
      "PromptLayerHandler\n",
      "GoogleTextSynthesizer\n",
      "MockLLM\n",
      "MockMongoDB\n",
      "BaseStructDatapointExtractor\n",
      "MongoDBKVStore\n",
      "LanceDBVectorStore\n",
      "CSVReader\n",
      "TextEmbeddingsInference\n",
      "SummaryIndexLLMRetriever\n",
      "ChatGPTRetrievalPluginClient\n",
      "WikipediaReader\n",
      "OpenAIAgentWorker\n",
      "QuestionsAnsweredExtractor\n",
      "RetrieverEvaluator\n",
      "BatchEvalRunner\n",
      "PineconeReader\n",
      "SimpleMultiModalQueryEngine\n",
      "OpenAIMultiModal\n",
      "FlatReader\n",
      "RedisIndexStore\n",
      "IngestionPipeline\n",
      "EmbeddingAdapterFinetuneEngine\n",
      "DashVectorReader\n",
      "SentenceEmbeddingOptimizer\n",
      "GradientModelAdapterLLM\n",
      "MockStreamChatLLM\n",
      "CachedOpenAIApiKeys\n",
      "Generation\n",
      "KVIndexStore\n",
      "AzureCosmosDBMongoDBVectorSearch\n",
      "Vllm\n",
      "WeaviateVectorStore\n",
      "TreeAllLeafRetriever\n",
      "CitationQueryEngine\n",
      "CallbackManager\n",
      "SimpleQueryToolNodeMapping\n",
      "BM25Retriever\n",
      "LanternVectorStore\n",
      "SemanticSimilarityEvaluator\n",
      "PineconeVectorStore\n",
      "LLMRailsEmbedding\n",
      "DeepLakeReader\n",
      "FaithfulnessEvaluator\n",
      "VideoAudioReader\n",
      "GuardrailsOutputParser\n",
      "WandbCallbackHandler\n",
      "DecomposeQueryTransform\n",
      "CogniswitchQueryEngine\n",
      "GithubRepositoryReader\n",
      "GoogleIndex\n",
      "QdrantVectorStore\n",
      "SQLTableRetrieverQueryEngine\n",
      "CohereRerankRelevancyMetric\n",
      "SQLStructStoreQueryEngine\n",
      "EmptyIndexRetriever\n",
      "Konko\n",
      "ToolRetrieverRouterQueryEngine\n",
      "SimpleChatEngine\n",
      "AdapterEmbeddingModel\n",
      "ObjectRetriever\n",
      "Neo4jVectorStore\n",
      "QueryEngineTool\n",
      "JSONQueryEngine\n",
      "OpenAIAssistantAgent\n",
      "MarvinMetadataExtractor\n",
      "ComposableGraph\n",
      "RetrieverQueryEngine\n",
      "BaseKeywordTableIndex\n",
      "Message\n",
      "KGTableRetriever\n",
      "RelevancyEvaluator\n",
      "MockVectorStore\n",
      "SQLAugmentQueryTransform\n",
      "DocumentSummaryIndexLLMRetriever\n",
      "TencentVectorDB\n",
      "RouterRetriever\n",
      "NLSQLTableQueryEngine\n",
      "ElevenLabsTTS\n",
      "LMFormatEnforcerPydanticProgram\n",
      "LangchainNodeParser\n",
      "NLSQLRetriever\n",
      "OpensearchVectorClient\n",
      "StreamingGeneratorCallbackHandler\n",
      "ContextRetrieverOpenAIAgent\n",
      "MistralAIEmbedding\n",
      "CohereRerank\n",
      "MockRefineProgram\n",
      "NebulaGraphStore\n",
      "CohereRerankerFinetuneEngine\n",
      "HuggingFaceInferenceAPI\n",
      "FirestoreDocumentStore\n",
      "RetrySourceQueryEngine\n",
      "JinaEmbedding\n",
      "MockFaissIndex\n",
      "KnowledgeGraphRAGRetriever\n",
      "EverlyAI\n",
      "ChromaVectorStore\n",
      "VectorIndexRetriever\n",
      "WeaviateReader\n",
      "KeywordExtractor\n",
      "MongoDBAtlasVectorSearch\n",
      "LLMTextCompletionProgram\n",
      "GuidancePydanticProgram\n",
      "BaseSQLTableQueryEngine\n",
      "DynamoDBIndexStore\n",
      "LiteLLM\n",
      "GPTTreeIndexBuilder\n",
      "PGVectorSQLQueryEngine\n",
      "OllamaEmbedding\n",
      "VellumPredictor\n",
      "FastEmbedEmbedding\n",
      "BaseComponent\n",
      "ChatMemoryBuffer\n",
      "Model\n"
     ]
    }
   ],
   "source": [
    "# for nodes with type method\n",
    "for n in G.nodes(data=True):\n",
    "    try:\n",
    "        if n[1]['type'] == 'method':\n",
    "            # get the predecessors\n",
    "            preds = G.predecessors(n[0])\n",
    "            print(n[0])\n",
    "            [print(G.nodes[p]['name']) for p in preds]\n",
    "            break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from chromadb import PersistentClient, HttpClient\n",
    "from chromadb.utils import embedding_functions\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def return_collection(path=None, collection_name=None):\n",
    "    assert path is not None, \"Path isn't specified\"\n",
    "    assert collection_name is not None, \"Collection name isn't specified\"\n",
    "    chroma_client = PersistentClient(path=path)\n",
    "    emb_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=os.getenv('OPENAI_API_KEY'),\n",
    "        model_name=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name, embedding_function=emb_fn, metadata={\"hnsw:space\": \"cosine\"})\n",
    "    return collection\n",
    "\n",
    "path_ = f\"{repo_id}/meta/storage\"\n",
    "explanations = return_collection(path=path_, collection_name=\"explanations\")\n",
    "explanations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = return_collection(path=path_, collection_name=\"code\")\n",
    "code.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets = return_collection(path=path_, collection_name=\"triplets\")\n",
    "triplets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['template_upload_pipeline function-call chunking_pipeline',\n",
       "  'template_upload_pipeline function-call embed_pipeline',\n",
       "  'template_upload_pipeline EXTERNAL_DEPENDENCY chunking_pipeline_0',\n",
       "  'template_upload_pipeline EXTERNAL_DEPENDENCY embed_pipeline_0',\n",
       "  'update_database.py function template_upload_pipeline',\n",
       "  'template_upload_pipeline function-call cot_pipeline',\n",
       "  'template_upload_pipeline EXTERNAL_DEPENDENCY cot_pipeline_0',\n",
       "  'chunking_pipeline EXTERNAL_DEPENDENCY open_files_0',\n",
       "  'embed.py function embed_pipeline',\n",
       "  'chunking_pipeline EXTERNAL_DEPENDENCY split_files_1']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What\"\n",
    "res = triplets.query(\n",
    "    query_texts=[query],\n",
    "    n_results=10\n",
    ")\n",
    "[r for r in res['documents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'containedin': 'update_database.py',\n",
       "   'index': '0',\n",
       "   'name': 'template_upload_pipeline',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'dfs.py',\n",
       "   'index': '2',\n",
       "   'name': 'cot_pipeline',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'embed.py',\n",
       "   'index': '3',\n",
       "   'name': 'embed_pipeline',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'chunker.py',\n",
       "   'index': '5',\n",
       "   'name': 'chunking_pipeline',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'embed.py',\n",
       "   'index': '0',\n",
       "   'name': 'get_embedding',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'agents.py',\n",
       "   'index': '1',\n",
       "   'name': 'create_assistant',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'embed.py',\n",
       "   'index': '1',\n",
       "   'name': 'open_data_json',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'agents.py',\n",
       "   'index': '2',\n",
       "   'name': 'create_thread',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'search.py',\n",
       "   'index': '1',\n",
       "   'name': 'open_embeddings_json',\n",
       "   'type': 'function'},\n",
       "  {'containedin': 'search.py',\n",
       "   'index': '0',\n",
       "   'name': 'open_data_json',\n",
       "   'type': 'function'}]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is happening with the template upload pipeline?\"\n",
    "res = code.query(\n",
    "    query_texts=[query],\n",
    "    n_results=10\n",
    ")\n",
    "[r for r in res['metadatas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[{'name': 'PDFReader', 'type': 'class'},\n",
       "   {'name': 'docstore', 'type': 'folder'},\n",
       "   {'name': 'BaseDocumentStore', 'type': 'class'},\n",
       "   {'name': 'BaseReader', 'type': 'class'},\n",
       "   {'name': 'DocArrayVectorStore', 'type': 'class'},\n",
       "   {'name': 'from_uri', 'type': 'method'},\n",
       "   {'name': 'DocxReader', 'type': 'class'},\n",
       "   {'name': 'VectorStoreQueryOutputParser', 'type': 'class'},\n",
       "   {'name': 'MilvusVectorStore', 'type': 'class'},\n",
       "   {'name': 'DocumentStoreType', 'type': 'class'}]],\n",
       " [['The code snippet defines a class called PDFReader that is a subclass of BaseReader. The class is used for parsing PDF files. It has two methods: __init__ and load_data. The __init__ method is used for initializing the PDFReader object, and the load_data method is used for loading data from the PDF file.',\n",
       "   'The code defines a method called \"docstore\" that belongs to a class. This method returns the value of a variable called \"_docstore\", which is expected to be an instance of the \"BaseDocumentStore\" class.',\n",
       "   'The code snippet defines a class called BaseDocumentStore. It is an abstract class that serves as a blueprint for other classes to inherit from. It contains a number of abstract methods that must be implemented by any class that inherits from it. These methods include functions for saving and loading data, adding and deleting documents, checking if a document exists, setting and getting document hashes, retrieving information about reference documents, and getting information about nodes. The actual implementation of these methods is not provided in the code snippet.',\n",
       "   'The code defines a class called BaseReader that serves as a base class for loading data from a directory. It has three methods: lazy_load_data, load_data, and load_langchain_documents. The purpose and functionality of these methods are not provided in the code snippet.',\n",
       "   'The code snippet defines a class called DocArrayVectorStore that is a subclass of VectorStore and ABC. It serves as a base class for creating a DocArray vector store. The class has several methods, including _update_ref_docs, _init_index, _find_docs_to_be_removed, client, num_docs, _get_schema, add, delete, and query. These methods are either abstract or have their implementation in the subclass. The class also has some attributes, such as _index, _schema, _ref_docs, stores_text, and flat_metadata.',\n",
       "   'The code snippet defines a class method called \"from_uri\" that creates and returns an instance of the \"MongoDocumentStore\" class. It takes in a MongoDB URI, an optional database name, and an optional namespace as arguments. Inside the method, it creates an instance of the \"MongoDBKVStore\" class using the URI and database name, and then uses that instance to create and return an instance of the \"MongoDocumentStore\" class.',\n",
       "   'The code defines a class called DocxReader that is a subclass of BaseReader. This class is used for parsing and reading Docx files. It has a method called load_data, which is not shown in the code snippet. The load_data method is responsible for loading the data from the Docx file.',\n",
       "   'The code snippet defines a class called VectorStoreQueryOutputParser that is a subclass of BaseOutputParser. It contains two methods, parse and format, but the details of what these methods do are not provided.',\n",
       "   'The code snippet defines a class called \"MilvusVectorStore\" which is a vector store implementation for storing text, its embedding, and metadata in a Milvus collection. The class has various optional arguments for configuring the connection to the Milvus server and the properties of the collection. It also has methods for adding, deleting, and querying data in the collection. The class also has a private method \"_create_index_if_required\" which is used internally to create an index for the collection if required.',\n",
       "   'The code defines a class called DocumentStoreType that inherits from the str class and Enum class. It has two attributes, MONGO and SIMPLE, which are string values representing different types of document stores.']]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"class to load pdf files into a store?\"\n",
    "res = explanations.query(\n",
    "    query_texts=[query],\n",
    "    n_results=10\n",
    ")\n",
    "[r for r in (res['metadatas'], res['documents'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('update_database.py', 'template_upload_pipeline', {'type': 'function'})\n",
      "('template_upload_pipeline', 'chunking_pipeline', {'type': 'function-call'})\n",
      "('template_upload_pipeline', 'embed_pipeline', {'type': 'function-call'})\n",
      "('template_upload_pipeline', 'cot_pipeline', {'type': 'function-call'})\n",
      "('template_upload_pipeline', 'chunking_pipeline_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('template_upload_pipeline', 'embed_pipeline_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('template_upload_pipeline', 'cot_pipeline_0', {'type': 'EXTERNAL_DEPENDENCY'})\n"
     ]
    }
   ],
   "source": [
    "for edge in G.edges(data=True):\n",
    "    if 'template_upload_pipeline' in edge:\n",
    "        print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the output connections, what comes out and where it coes in (a train of events). How the functions are being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chunker.py', 'chunking_pipeline', {'type': 'function'})\n",
      "('chunking_pipeline', 'open_files', {'type': 'function-call'})\n",
      "('chunking_pipeline', 'extract_education_and_experience', {'type': 'function-call'})\n",
      "('chunking_pipeline', 'store_data', {'type': 'function-call'})\n",
      "('chunking_pipeline', 'open_files_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('chunking_pipeline', 'split_files_1', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('chunking_pipeline', 'extract_education_and_experience_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('chunking_pipeline', 'store_data_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('template_upload_pipeline', 'chunking_pipeline', {'type': 'function-call'})\n"
     ]
    }
   ],
   "source": [
    "for edge in G.edges(data=True):\n",
    "    if 'chunking_pipeline' in edge:\n",
    "        print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
