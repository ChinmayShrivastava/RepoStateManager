{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 16207 nodes and 36362 edges\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "repo_id = '45526e5b-f544-4016-8381-f88f5ca095ea'\n",
    "G = pickle.load(open(repo_id+'/state_0.pkl', 'rb'))\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_into_table', '\"split_text_metadata_aware\"', 'get_request_body', 'Method Goes Here: from_args', '_select', '_validate_index', '_aretrieve', 'query', '_normalise_metadata_to_index_fields', 'dir-to-file', '_get_prompts', 'agenerate_query', '_create_collection', 'imports_directly', 'from_uri', 'class-instance', 'run_sql', '_to_typesense_filter', 'REQUIRED_TYPE', '_create_odata_filter', 'completion_to_prompt', 'EXTERNAL_DEPENDENCY', 'class', 'get_formatted_sources', 'flat_metadata', 'function', 'stores_text', 'get_text_from_stream_response', '_create_index', 'get_usable_table_names', 'get_single_table_info', '_update_prompts', 'get_table_columns', '\"llm\"', 'function-call', '_retrieve', 'parent_class', '_get_prompt_modules', '\"split_text\"', '\"predict\"', 'METHOD', '_create_upsert_docs', '_create_index_if_not_exists', 'is_embedding_query', 'Any]', '_delete_node', 'as_retriever', 'dir-to-dir', '_default_index_mapping', '_create_index_document', 'print_response_stream', 'delete', 'PROPERTY', 'client', 'ref_doc_info', 'class-method', 'Method Goes Here: aretrieve', '__property__', 'add', 'imports_from', '_aquery', '_build_index_from_nodes', 'generate_query', 'REQUIRED_KEYS', '_create_metadata_index_fields', 'get_response', '__str__', 'arbitrary_types_allowed', '__init__', 'max_tokens_key', 'messages_to_prompt', '_insert', '\"apredict\"', 'get_text_from_response', 'is_a_submodule_of', 'Method Goes Here: with_retriever', '_query', 'collection', '\"metadata\"', 'root-to-dir'}\n"
     ]
    }
   ],
   "source": [
    "# G.nodes(data=True)['Superagent']\n",
    "# for edge in G.edges('BaseOpenAIAgent', data=True):\n",
    "#     print(edge)\n",
    "#     break\n",
    "\n",
    "# G.nodes(data=True)['__init__']\n",
    "\n",
    "# print all unique edge types\n",
    "edge_types = set()\n",
    "for edge in G.edges(data=True):\n",
    "    edge_types.add(edge[2]['type'])\n",
    "print(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'info', 'function', 'file', 'external_module', 'element', 'external_library', 'class', 'method', 'folder'}\n"
     ]
    }
   ],
   "source": [
    "# print the unique node types\n",
    "node_types = set()\n",
    "for node in G.nodes(data=True):\n",
    "    if 'type' in node[1]:\n",
    "        node_types.add(node[1]['type'])\n",
    "print(node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '__init__',\n",
       " 'type': 'method',\n",
       " 'start_line': 11,\n",
       " 'end_line': 33,\n",
       " 'explanation': 'The code snippet is defining a class with an initializer method. The initializer method takes in three optional parameters: host, port, and uri. It initializes a MongoClient object from the pymongo library based on the provided parameters. If the uri parameter is provided, it creates the MongoClient object using the uri. If the host and port parameters are provided, it creates the MongoClient object using the host and port. If neither the uri nor the host and port parameters are provided, it raises a ValueError. The MongoClient object is then assigned to the class attribute self.client.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes(data=True)['__init__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n",
      "SimpleMongoReader\n",
      "RocksetVectorStore\n",
      "SQLJoinQueryEngine\n",
      "BaseStructStoreIndex\n",
      "SentenceSplitter\n",
      "TreeSummarize\n",
      "IPYNBReader\n",
      "AzureOpenAIEmbedding\n",
      "Perplexity\n",
      "CassandraVectorStore\n",
      "LlamaCPP\n",
      "FaissVectorStore\n",
      "LangchainPromptTemplate\n",
      "LLMMultiSelector\n",
      "BagelVectorStore\n",
      "AimCallback\n",
      "DFFullProgram\n",
      "OpenAIQuestionGenerator\n",
      "CondenseQuestionChatEngine\n",
      "DocumentSummaryIndex\n",
      "GoogleVectorStore\n",
      "FaissReader\n",
      "MockChatLLM\n",
      "OpenLLM\n",
      "ZepVectorStore\n",
      "LinearLayer\n",
      "Accumulate\n",
      "EvaporateExtractor\n",
      "CondensePlusContextChatEngine\n",
      "PaLM\n",
      "PGVectoRsStore\n",
      "NLStructStoreQueryEngine\n",
      "ElasticsearchReader\n",
      "SlackReader\n",
      "OpenAIEmbedding\n",
      "ReActAgent\n",
      "MongoDocumentStore\n",
      "OpenAI\n",
      "Neo4jGraphStore\n",
      "Anthropic\n",
      "MetaProvider\n",
      "MultiModalVectorIndexRetriever\n",
      "Refine\n",
      "AwadbReader\n",
      "GradientBaseModelLLM\n",
      "GradientFinetuneEngine\n",
      "VectorStoreIndex\n",
      "OpenAIFinetuneEngine\n",
      "LangchainEmbedding\n",
      "SQLDatabase\n",
      "FirestoreKVStore\n",
      "SummaryExtractor\n",
      "LLMPredictor\n",
      "OnDemandLoaderTool\n",
      "WatsonX\n",
      "PandasIndex\n",
      "MetalVectorStore\n",
      "PGVectorSQLParser\n",
      "DocArrayInMemoryVectorStore\n",
      "DiscordReader\n",
      "TokenCountingHandler\n",
      "UnstructuredElementNodeParser\n",
      "S3DBKVStore\n",
      "PDFReader\n",
      "BufferedGitBlobDataIterator\n",
      "QdrantReader\n",
      "ReplicateMultiModal\n",
      "OpensearchVectorStore\n",
      "MultiModalRetrieverEvaluator\n",
      "SummaryIndexRetriever\n",
      "SimpleSummarize\n",
      "MockObject2\n",
      "ColbertIndex\n",
      "FakeGoogleDataclass\n",
      "ElasticsearchStore\n",
      "SQLStructDatapointExtractor\n",
      "TreeSelectLeafRetriever\n",
      "TwoLayerNN\n",
      "LLMLookaheadAnswerInserter\n",
      "MockForkStepEngine\n",
      "MockIBMModelModule\n",
      "BarkTTS\n",
      "DatasetGenerator\n",
      "SentenceTransformersFinetuneEngine\n",
      "ZillizCloudPipelineRetriever\n",
      "HuggingFaceLLM\n",
      "DynamoDBDocumentStore\n",
      "RssReader\n",
      "AnthropicProvider\n",
      "TransformRetriever\n",
      "TitleExtractor\n",
      "MilvusVectorStore\n",
      "SQLTableNodeMapping\n",
      "BaseOpenAIAgent\n",
      "MboxReader\n",
      "_BaseGradientLLM\n",
      "MultiModalRelevancyEvaluator\n",
      "EpsillaVectorStore\n",
      "FeedbackQueryTransformation\n",
      "MyScaleReader\n",
      "RedisDocumentStore\n",
      "AsyncParamTuner\n",
      "TypesenseVectorStore\n",
      "GuidanceQuestionGenerator\n",
      "MockMongoCollection\n",
      "MyScaleVectorStore\n",
      "ContextChatEngine\n",
      "FunctionTool\n",
      "ObjectIndex\n",
      "SimpleKVStore\n",
      "ChatPromptTemplate\n",
      "KuzuGraphStore\n",
      "MonsterLLM\n",
      "RetrieverTool\n",
      "PsychicReader\n",
      "JSONReader\n",
      "DocArrayHnswVectorStore\n",
      "PromptHelper\n",
      "MetalReader\n",
      "BeirEvaluator\n",
      "Vertex\n",
      "SimpleVectorStore\n",
      "ClarifaiEmbedding\n",
      "TestLLM\n",
      "SummaryIndexEmbeddingRetriever\n",
      "BeautifulSoupWebReader\n",
      "SimpleObjectNodeMapping\n",
      "SQLDocumentContextBuilder\n",
      "BaseIndex\n",
      "MultiModalLLMCompletionProgram\n",
      "BaseFinetuningHandler\n",
      "CognitiveSearchVectorStore\n",
      "PairwiseComparisonEvaluator\n",
      "BaseSynthesizer\n",
      "HTMLTagReader\n",
      "GlobalsHelper\n",
      "SQLStructStoreIndex\n",
      "MockOutputParser\n",
      "VectorIndexAutoRetriever\n",
      "Xinference\n",
      "BaseEvaporateProgram\n",
      "PptxReader\n",
      "MyScaleSettings\n",
      "FirestoreIndexStore\n",
      "LlamaLogger\n",
      "FlagEmbeddingReranker\n",
      "DynamoDBVectorStore\n",
      "LongLLMLinguaPostprocessor\n",
      "QueryFusionRetriever\n",
      "TokenCounter\n",
      "DFRowsProgram\n",
      "EmbeddingSingleSelector\n",
      "NoSuchCorpusException\n",
      "TreeIndexInserter\n",
      "CrossEncoderFinetuneEngine\n",
      "MockEvaluator\n",
      "LlamaDebugHandler\n",
      "TreeIndex\n",
      "HuggingFaceEmbedding\n",
      "MilvusReader\n",
      "GeminiEmbedding\n",
      "SQLAutoVectorQueryEngine\n",
      "LangChainLLM\n",
      "QASummaryQueryEngineBuilder\n",
      "KnowledgeGraphQueryEngine\n",
      "GradientEmbedding\n",
      "ReActAgentWorker\n",
      "RetryQueryEngine\n",
      "BaseTTS\n",
      "HotpotQARetriever\n",
      "MockEmbedding\n",
      "VellumPromptRegistry\n",
      "SimpleIndexStore\n",
      "MistralAI\n",
      "DocumentSummaryIndexEmbeddingRetriever\n",
      "DeepLakeVectorStore\n",
      "KVDocumentStore\n",
      "PandasCSVReader\n",
      "KnowledgeGraphIndex\n",
      "GuidelineEvaluator\n",
      "RetryGuidelineQueryEngine\n",
      "TimescaleVectorStore\n",
      "AwaDBVectorStore\n",
      "DatabaseReader\n",
      "TokenEscaper\n",
      "SubQuestionQueryEngine\n",
      "FLAREInstructQueryEngine\n",
      "ImageVisionLLMReader\n",
      "Portkey\n",
      "TwitterTweetReader\n",
      "ClipEmbedding\n",
      "NotionPageReader\n",
      "OpenAIPydanticProgram\n",
      "SimpleDirectoryReader\n",
      "ObsidianReader\n",
      "BaseRetriever\n",
      "CollectionParams\n",
      "YouRetriever\n",
      "RecursiveRetriever\n",
      "TrafilaturaWebReader\n",
      "IsDoneOutputParser\n",
      "AstraDBVectorStore\n",
      "OpenAIAgent\n",
      "EmptyIndex\n",
      "RouterQueryEngine\n",
      "EventContext\n",
      "SteamshipFileReader\n",
      "MultiModalFaithfulnessEvaluator\n",
      "TreeRootRetriever\n",
      "Clarifai\n",
      "LangchainOutputParser\n",
      "FalkorDBGraphStore\n",
      "LlamaAPI\n",
      "VectaraIndex\n",
      "MultiModalVectorStoreIndex\n",
      "ImageReader\n",
      "GeminiMultiModal\n",
      "ImageCaptionReader\n",
      "FilterField\n",
      "BagelReader\n",
      "Cohere\n",
      "RetrieverRouterQueryEngine\n",
      "SentenceTransformerRerank\n",
      "MongoIndexStore\n",
      "PydanticMultiSelector\n",
      "MyMultipleNegativesRankingLoss\n",
      "AI21\n",
      "GoogleUnivSentEncoderEmbedding\n",
      "SimpleLLMHandler\n",
      "GoogleSheetsReader\n",
      "RagDatasetGenerator\n",
      "ChromaReader\n",
      "OpenRouter\n",
      "AutoMergingRetriever\n",
      "CohereEmbedding\n",
      "PydanticSingleSelector\n",
      "LLMRerank\n",
      "MultiStepQueryEngine\n",
      "PromptTemplate\n",
      "LLMQuestionGenerator\n",
      "ChatGPTRetrievalPluginReader\n",
      "ConditionalException\n",
      "HWPReader\n",
      "InstructorEmbedding\n",
      "VectaraQueryEngine\n",
      "SingleStoreVectorStore\n",
      "NotionToolSpec\n",
      "EntityExtractor\n",
      "SimpleDocumentStore\n",
      "RedisKVStore\n",
      "Bedrock\n",
      "TairVectorStore\n",
      "HyDEQueryTransform\n",
      "VoyageEmbedding\n",
      "MockMongoClient\n",
      "PandasQueryEngine\n",
      "SlackToolSpec\n",
      "SelectorPromptTemplate\n",
      "ImageOutputQueryTransform\n",
      "SimpleWebPageReader\n",
      "DashVectorStore\n",
      "GooglePaLMEmbedding\n",
      "SQLContextContainerBuilder\n",
      "DefaultRefineProgram\n",
      "AzureOpenAI\n",
      "RedisVectorStore\n",
      "TestSQLDatabase\n",
      "BufferedAsyncIterator\n",
      "PGVectorStore\n",
      "MockStreamCompletionWithRetry\n",
      "BedrockEmbedding\n",
      "OptimumEmbedding\n",
      "TokenTextSplitter\n",
      "Playground\n",
      "OpenLLMAPI\n",
      "PredibaseLLM\n",
      "MockPineconeIndex\n",
      "ComposableGraphQueryEngine\n",
      "StepDecomposeQueryTransform\n",
      "RunGptLLM\n",
      "GoogleDocsReader\n",
      "BaseKeywordTableRetriever\n",
      "SupabaseVectorStore\n",
      "MockAgentWorker\n",
      "QueryPlanTool\n",
      "SummaryIndex\n",
      "LocalAI\n",
      "BaseCallbackHandler\n",
      "MetadataReplacementPostProcessor\n",
      "MockObject1\n",
      "OpenInferenceCallbackHandler\n",
      "BaseQueryEngine\n",
      "ColbertRetriever\n",
      "SQLRetriever\n",
      "MarkdownReader\n",
      "BaseManagedIndex\n",
      "SimpleToolNodeMapping\n",
      "LoadAndSearchToolSpec\n",
      "Anyscale\n",
      "TransformQueryEngine\n",
      "CorrectnessEvaluator\n",
      "DynamoDBKVStore\n",
      "LLMSingleSelector\n",
      "BaseToolAsyncAdapter\n",
      "VllmServer\n",
      "PydanticOutputParser\n",
      "VectaraRetriever\n",
      "AgentRunner\n",
      "ZillizCloudPipelineIndex\n",
      "ParallelAgentRunner\n",
      "GithubClient\n",
      "ElasticsearchEmbedding\n",
      "Gemini\n",
      "SimpleGraphStore\n",
      "Phone\n",
      "PromptLayerHandler\n",
      "GoogleTextSynthesizer\n",
      "MockLLM\n",
      "MockMongoDB\n",
      "BaseStructDatapointExtractor\n",
      "MongoDBKVStore\n",
      "LanceDBVectorStore\n",
      "CSVReader\n",
      "TextEmbeddingsInference\n",
      "SummaryIndexLLMRetriever\n",
      "ChatGPTRetrievalPluginClient\n",
      "WikipediaReader\n",
      "OpenAIAgentWorker\n",
      "QuestionsAnsweredExtractor\n",
      "RetrieverEvaluator\n",
      "BatchEvalRunner\n",
      "PineconeReader\n",
      "SimpleMultiModalQueryEngine\n",
      "OpenAIMultiModal\n",
      "FlatReader\n",
      "RedisIndexStore\n",
      "IngestionPipeline\n",
      "EmbeddingAdapterFinetuneEngine\n",
      "DashVectorReader\n",
      "SentenceEmbeddingOptimizer\n",
      "GradientModelAdapterLLM\n",
      "MockStreamChatLLM\n",
      "CachedOpenAIApiKeys\n",
      "Generation\n",
      "KVIndexStore\n",
      "AzureCosmosDBMongoDBVectorSearch\n",
      "Vllm\n",
      "WeaviateVectorStore\n",
      "TreeAllLeafRetriever\n",
      "CitationQueryEngine\n",
      "CallbackManager\n",
      "SimpleQueryToolNodeMapping\n",
      "BM25Retriever\n",
      "LanternVectorStore\n",
      "SemanticSimilarityEvaluator\n",
      "PineconeVectorStore\n",
      "LLMRailsEmbedding\n",
      "DeepLakeReader\n",
      "FaithfulnessEvaluator\n",
      "VideoAudioReader\n",
      "GuardrailsOutputParser\n",
      "WandbCallbackHandler\n",
      "DecomposeQueryTransform\n",
      "CogniswitchQueryEngine\n",
      "GithubRepositoryReader\n",
      "GoogleIndex\n",
      "QdrantVectorStore\n",
      "SQLTableRetrieverQueryEngine\n",
      "CohereRerankRelevancyMetric\n",
      "SQLStructStoreQueryEngine\n",
      "EmptyIndexRetriever\n",
      "Konko\n",
      "ToolRetrieverRouterQueryEngine\n",
      "SimpleChatEngine\n",
      "AdapterEmbeddingModel\n",
      "ObjectRetriever\n",
      "Neo4jVectorStore\n",
      "QueryEngineTool\n",
      "JSONQueryEngine\n",
      "OpenAIAssistantAgent\n",
      "MarvinMetadataExtractor\n",
      "ComposableGraph\n",
      "RetrieverQueryEngine\n",
      "BaseKeywordTableIndex\n",
      "Message\n",
      "KGTableRetriever\n",
      "RelevancyEvaluator\n",
      "MockVectorStore\n",
      "SQLAugmentQueryTransform\n",
      "DocumentSummaryIndexLLMRetriever\n",
      "TencentVectorDB\n",
      "RouterRetriever\n",
      "NLSQLTableQueryEngine\n",
      "ElevenLabsTTS\n",
      "LMFormatEnforcerPydanticProgram\n",
      "LangchainNodeParser\n",
      "NLSQLRetriever\n",
      "OpensearchVectorClient\n",
      "StreamingGeneratorCallbackHandler\n",
      "ContextRetrieverOpenAIAgent\n",
      "MistralAIEmbedding\n",
      "CohereRerank\n",
      "MockRefineProgram\n",
      "NebulaGraphStore\n",
      "CohereRerankerFinetuneEngine\n",
      "HuggingFaceInferenceAPI\n",
      "FirestoreDocumentStore\n",
      "RetrySourceQueryEngine\n",
      "JinaEmbedding\n",
      "MockFaissIndex\n",
      "KnowledgeGraphRAGRetriever\n",
      "EverlyAI\n",
      "ChromaVectorStore\n",
      "VectorIndexRetriever\n",
      "WeaviateReader\n",
      "KeywordExtractor\n",
      "MongoDBAtlasVectorSearch\n",
      "LLMTextCompletionProgram\n",
      "GuidancePydanticProgram\n",
      "BaseSQLTableQueryEngine\n",
      "DynamoDBIndexStore\n",
      "LiteLLM\n",
      "GPTTreeIndexBuilder\n",
      "PGVectorSQLQueryEngine\n",
      "OllamaEmbedding\n",
      "VellumPredictor\n",
      "FastEmbedEmbedding\n",
      "BaseComponent\n",
      "ChatMemoryBuffer\n",
      "Model\n"
     ]
    }
   ],
   "source": [
    "# for nodes with type method\n",
    "method_ = []\n",
    "for n in G.nodes(data=True):\n",
    "    try:\n",
    "        if n[1]['type'] == 'method':\n",
    "            # get the predecessors\n",
    "            preds = G.predecessors(n[0])\n",
    "            print(n[0])\n",
    "            [print(G.nodes[p]['name']) for p in preds]\n",
    "            break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from chromadb import PersistentClient, HttpClient\n",
    "from chromadb.utils import embedding_functions\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def return_collection(path=None, collection_name=None):\n",
    "    assert path is not None, \"Path isn't specified\"\n",
    "    assert collection_name is not None, \"Collection name isn't specified\"\n",
    "    chroma_client = PersistentClient(path=path)\n",
    "    emb_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=os.getenv('OPENAI_API_KEY'),\n",
    "        model_name=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name, embedding_function=emb_fn, metadata={\"hnsw:space\": \"cosine\"})\n",
    "    return collection\n",
    "\n",
    "path_ = f\"{repo_id}/meta/storage\"\n",
    "explanations = return_collection(path=path_, collection_name=\"explanations\")\n",
    "explanations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = return_collection(path=path_, collection_name=\"code\")\n",
    "code.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36362"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets = return_collection(path=path_, collection_name=\"triplets\")\n",
    "triplets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PDFReader REQUIRED_TYPE a class that implements the load_data method',\n",
       "  'ClipEmbedding class-instance load',\n",
       "  'MilvusReader class-instance load',\n",
       "  'PDFReader class-instance update',\n",
       "  'GoogleDocsReader class-instance documents',\n",
       "  'load_document class-instance load_data',\n",
       "  'get_module_info class-instance load',\n",
       "  'load_examples class-instance load',\n",
       "  'docs_reader.py class PDFReader',\n",
       "  'PDFReader class-method load_data']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the class to load PDFs?\"\n",
    "res = triplets.query(\n",
    "    query_texts=[query],\n",
    "    n_results=10\n",
    ")\n",
    "[r for r in res['documents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'containedin': '@@llama_index@@readers@@file@@docs_reader.py',\n",
       "   'index': '0',\n",
       "   'name': 'PDFReader',\n",
       "   'type': 'class'},\n",
       "  {'containedin': '@@llama_index@@readers@@base.py',\n",
       "   'index': '0',\n",
       "   'name': 'BaseReader',\n",
       "   'type': 'class'},\n",
       "  {'containedin': '@@llama_index@@download@@dataset.py',\n",
       "   'index': '0',\n",
       "   'name': '_resolve_dataset_file_name',\n",
       "   'type': 'function'},\n",
       "  {'containedin': '@@llama_index@@download@@module.py',\n",
       "   'index': '2',\n",
       "   'name': 'download_llama_module',\n",
       "   'type': 'function'},\n",
       "  {'containedin': '@@llama_index@@readers@@base.py',\n",
       "   'index': '1',\n",
       "   'name': 'BasePydanticReader',\n",
       "   'type': 'class'},\n",
       "  {'containedin': '@@llama_index@@readers@@loading.py',\n",
       "   'index': '0',\n",
       "   'name': 'load_reader',\n",
       "   'type': 'function'},\n",
       "  {'containedin': '@@llama_index@@download@@module.py',\n",
       "   'index': '1',\n",
       "   'name': 'download_module_and_reqs',\n",
       "   'type': 'function'},\n",
       "  {'containedin': '@@llama_index@@readers@@base.py',\n",
       "   'index': '2',\n",
       "   'name': 'ReaderConfig',\n",
       "   'type': 'class'},\n",
       "  {'containedin': '@@tests@@readers@@test_load_reader.py',\n",
       "   'index': '0',\n",
       "   'name': 'test_loading_readers',\n",
       "   'type': 'function'},\n",
       "  {'containedin': '@@llama_index@@download@@dataset.py',\n",
       "   'index': '4',\n",
       "   'name': 'download_llama_dataset',\n",
       "   'type': 'function'}]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the class to load PDFs?\"\n",
    "res = code.query(\n",
    "    query_texts=[query],\n",
    "    n_results=10\n",
    ")\n",
    "[r for r in res['metadatas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[{'name': 'PDFReader', 'type': 'class'},\n",
       "   {'name': 'DocxReader', 'type': 'class'},\n",
       "   {'name': 'BaseReader', 'type': 'class'},\n",
       "   {'name': 'GoogleDocsReader', 'type': 'class'},\n",
       "   {'name': 'BagelReader', 'type': 'class'},\n",
       "   {'name': 'TrafilaturaWebReader', 'type': 'class'},\n",
       "   {'name': 'ImageReader', 'type': 'class'},\n",
       "   {'name': 'ChatGPTRetrievalPluginReader', 'type': 'class'},\n",
       "   {'name': 'GoogleSheetsReader', 'type': 'class'},\n",
       "   {'name': 'ChromaReader', 'type': 'class'}]],\n",
       " [['The code snippet defines a class called PDFReader that is a subclass of BaseReader. The class is used for parsing PDF files. It has two methods: __init__ and load_data. The __init__ method is used for initializing the PDFReader object, and the load_data method is used for loading data from the PDF file.',\n",
       "   'The code defines a class called DocxReader that is a subclass of BaseReader. This class is used for parsing and reading Docx files. It has a method called load_data, which is not shown in the code snippet. The load_data method is responsible for loading the data from the Docx file.',\n",
       "   'The code defines a class called BaseReader that serves as a base class for loading data from a directory. It has three methods: lazy_load_data, load_data, and load_langchain_documents. The purpose and functionality of these methods are not provided in the code snippet.',\n",
       "   'The code defines a class called GoogleDocsReader that inherits from the BasePydanticReader class. This class is used to read a page from Google Docs. It has several methods, including __init__, class_name, load_data, _load_doc, _get_credentials, _read_paragraph_element, and _read_structural_elements. The purpose and functionality of these methods are not provided in the code snippet.',\n",
       "   'The code defines a class called BagelReader that is a subclass of BaseReader. It has three methods: __init__, create_documents, and load_data. The __init__ method is the constructor for the class. The create_documents method is used to create documents. The load_data method is used to load data.',\n",
       "   'The code defines a class called \"TrafilaturaWebReader\" that is a subclass of \"BasePydanticReader\". This class is used to read web pages using the \"trafilatura\" package. \\n\\nThe class has two attributes: \"is_remote\" which is a boolean indicating if the web page is remote or not, and \"error_on_missing\" which is a boolean indicating if an error should be raised if the web page is missing.\\n\\nThe class also has three methods: \"__init__\", \"class_name\", and \"load_data\". The \"__init__\" method is the constructor for the class, the \"class_name\" method returns the name of the class, and the \"load_data\" method is used to load the data from the web page.',\n",
       "   'The code defines a class called ImageReader that is a subclass of BaseReader. It is used to extract text from images using a tool called DONUT. The class has two methods: __init__ and load_data. The __init__ method is used to initialize the ImageReader object, and the load_data method is used to load the image data for processing.',\n",
       "   'The code snippet defines a class called ChatGPTRetrievalPluginReader that is a subclass of BaseReader. It has two methods: __init__ and load_data. The __init__ method is used to initialize the object of the class, and the load_data method is used to load data for the retrieval plugin.',\n",
       "   'The code defines a class called GoogleSheetsReader that is a subclass of BasePydanticReader. This class is used to read data from a Google Sheets document. \\n\\nThe class has several methods, including __init__, class_name, load_data, _load_sheet, and _get_credentials. These methods are used to initialize the class, get the class name, load the data from the Google Sheets document, load the specific sheet from the document, and get the credentials needed to access the Google Sheets API, respectively. \\n\\nThe class also has a variable called is_remote, which is set to True. This variable indicates that the data is being read from a remote source (Google Sheets) rather than a local file.',\n",
       "   'The code defines a class called ChromaReader that inherits from the BaseReader class. The ChromaReader class is used to retrieve documents from existing persisted Chroma collections. It has three methods: __init__, create_documents, and load_data.\\n\\nThe __init__ method is the constructor of the class. It takes two arguments: collection_name and persist_directory. It initializes the ChromaReader object with the provided collection name and persist directory.\\n\\nThe create_documents method is used to create documents in the Chroma collection. It takes a list of documents as an argument and adds them to the collection.\\n\\nThe load_data method is used to load data from the Chroma collection. It takes no arguments and returns the loaded data.']]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the class to load PDFs?\"\n",
    "res = explanations.query(\n",
    "    query_texts=[query],\n",
    "    n_results=10\n",
    ")\n",
    "[r for r in (res['metadatas'], res['documents'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('update_database.py', 'template_upload_pipeline', {'type': 'function'})\n",
      "('template_upload_pipeline', 'chunking_pipeline', {'type': 'function-call'})\n",
      "('template_upload_pipeline', 'embed_pipeline', {'type': 'function-call'})\n",
      "('template_upload_pipeline', 'cot_pipeline', {'type': 'function-call'})\n",
      "('template_upload_pipeline', 'chunking_pipeline_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('template_upload_pipeline', 'embed_pipeline_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('template_upload_pipeline', 'cot_pipeline_0', {'type': 'EXTERNAL_DEPENDENCY'})\n"
     ]
    }
   ],
   "source": [
    "for edge in G.edges(data=True):\n",
    "    if 'template_upload_pipeline' in edge:\n",
    "        print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the output connections, what comes out and where it coes in (a train of events). How the functions are being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chunker.py', 'chunking_pipeline', {'type': 'function'})\n",
      "('chunking_pipeline', 'open_files', {'type': 'function-call'})\n",
      "('chunking_pipeline', 'extract_education_and_experience', {'type': 'function-call'})\n",
      "('chunking_pipeline', 'store_data', {'type': 'function-call'})\n",
      "('chunking_pipeline', 'open_files_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('chunking_pipeline', 'split_files_1', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('chunking_pipeline', 'extract_education_and_experience_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('chunking_pipeline', 'store_data_0', {'type': 'EXTERNAL_DEPENDENCY'})\n",
      "('template_upload_pipeline', 'chunking_pipeline', {'type': 'function-call'})\n"
     ]
    }
   ],
   "source": [
    "for edge in G.edges(data=True):\n",
    "    if 'chunking_pipeline' in edge:\n",
    "        print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
