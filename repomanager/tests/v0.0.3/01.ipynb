{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager/repomanager/tests/v0.0.3', '/Users/chinmayshrivastava/anaconda3/lib/python311.zip', '/Users/chinmayshrivastava/anaconda3/lib/python3.11', '/Users/chinmayshrivastava/anaconda3/lib/python3.11/lib-dynload', '', '/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager/venv/lib/python3.11/site-packages', '/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager/repomanager']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# append the path of the parent directory to sys.path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "print(sys.path)\n",
    "\n",
    "repo_name = \"llama_index\"\n",
    "repo_id = \"45526e5b-f544-4016-8381-f88f5ca095ea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the parent directory\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager/repomanager'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager/venv/lib/python3.11/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager/repomanager/tests/v0.0.3', '/Users/chinmayshrivastava/anaconda3/lib/python311.zip', '/Users/chinmayshrivastava/anaconda3/lib/python3.11', '/Users/chinmayshrivastava/anaconda3/lib/python3.11/lib-dynload', '', '/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager/venv/lib/python3.11/site-packages', '/Users/chinmayshrivastava/Documents/GitHub/RepoStateManager/repomanager']\n"
     ]
    }
   ],
   "source": [
    "from statemanager.graph._graph import NetworkXGraph\n",
    "from statemanager.vspace.vsearch import VectorSearch\n",
    "import pickle\n",
    "\n",
    "print(sys.path)\n",
    "G = pickle.load(open(\"statemanager/state/{repoid}/state_0.pkl\".format(repoid=repo_id), \"rb\"))\n",
    "\n",
    "graph = NetworkXGraph.from_G(\n",
    "    repo_id=repo_id,\n",
    "    G=G,\n",
    ")\n",
    "\n",
    "explanations = VectorSearch(\n",
    "    collection_name=\"explanations\",\n",
    "    collection_path=\"statemanager/state/{repoid}/meta/storage\".format(repoid=repo_id),\n",
    ")\n",
    "\n",
    "code = VectorSearch(\n",
    "    collection_name=\"code\",\n",
    "    collection_path=\"statemanager/state/{repoid}/meta/storage\".format(repoid=repo_id),\n",
    ")\n",
    "\n",
    "triplets = VectorSearch(\n",
    "    collection_name=\"triplets\",\n",
    "    collection_path=\"statemanager/state/{repoid}/meta/storage\".format(repoid=repo_id),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 16207 nodes and 36362 edges\n"
     ]
    }
   ],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'OpenAIAgent', 'type': 'class', 'index': '0', 'elementname': '@@llama_index@@agent@@openai@@base!!class!!0!!OpenAIAgent.py', 'explanation': 'The code snippet defines a class called OpenAIAgent that is a subclass of AgentRunner. It also includes a method called __init__ and a class method called from_tools. The purpose and functionality of these methods are not provided in the code snippet.', 'info': {'generated': True, 'date_modified': '2023-12-26 23:48:44', 'n_info_edges': 3}}\n"
     ]
    }
   ],
   "source": [
    "# get the info related to a node\n",
    "node = \"OpenAIAgent\"\n",
    "print(graph.G.nodes[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class OpenAIAgent(AgentRunner):\n",
      "    \"\"\"OpenAI agent.\n",
      "\n",
      "    Subclasses AgentRunner with a OpenAIAgentWorker.\n",
      "\n",
      "    For the legacy implementation see:\n",
      "    ```python\n",
      "    from llama_index.agent.legacy.openai.base import OpenAIAgent\n",
      "    ```\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "Method Goes Here -> Method name is '__init__'\n",
      "\n",
      "    @classmethod\n",
      "Method Goes Here -> Method name is 'from_tools'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_code = graph.get_code(\n",
    "    node_metadata={\n",
    "        \"name\": \"OpenAIAgent\",\n",
    "        \"elementname\": '@@llama_index@@agent@@openai@@base!!class!!0!!OpenAIAgent.py',\n",
    "        \"type\": \"class\",\n",
    "    },\n",
    "    elementname='@@llama_index@@agent@@openai@@base!!class!!0!!OpenAIAgent.py',\n",
    "    )\n",
    "\n",
    "print(_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations.collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36362"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets.collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> fun things below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>> idea is to have a single query to a node return sufficient responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to take in a query and return the exact class/function/method associated with it?\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "1. In a code library the classes are the most important element, so everything will relate to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['FalkorDBGraphStore', 'Neo4jGraphStore', 'KnowledgeGraphIndex']]\n",
      "[[0.19102251529693604, 0.20704853534698486, 0.21886539459228516]]\n"
     ]
    }
   ],
   "source": [
    "query = \"connect to a graphdb\"\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['ids'])\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KnowledgeGraphQueryEngine', 'KnowledgeGraphIndex', 'FalkorDBGraphStore']]\n",
      "[[0.19565218687057495, 0.21132677793502808, 0.22732490301132202]]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Find relevant class that contains context to answer the question:\n",
    "Question: connect to a graphdb\"\"\"\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['ids'])\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ChatMemoryBuffer', 'TokenCountingHandler', 'TokenCountingEvent']]\n",
      "[[0.20348596572875977, 0.22718793153762817, 0.2411128282546997]]\n"
     ]
    }
   ],
   "source": [
    "query = \"When using memory = ChatMemoryBuffer.from_defaults(token_limit=YOUR_LIMIT) to remove old history and limit token usage, is there a way to detect when the memory limit is hit and print a notification every time it happens?\"\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['ids'])\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'explanations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFind relevant class, function or method that contains context to answer the question:\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mQuestion: When using memory = ChatMemoryBuffer.from_defaults(token_limit=YOUR_LIMIT) to remove old history and limit token usage, is there a way to detect when the memory limit is hit and print a notification every time it happens?\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mexplanations\u001b[49m\u001b[38;5;241m.\u001b[39msearch_all(query, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(explanations\u001b[38;5;241m.\u001b[39msearch_all(query, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistances\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'explanations' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Find relevant class that contains context to answer the question:\n",
    "Question: When using memory = ChatMemoryBuffer.from_defaults(token_limit=YOUR_LIMIT) to remove old history and limit token usage, is there a way to detect when the memory limit is hit and print a notification every time it happens?\"\"\"\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['ids'])\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DocumentSummaryIndex', 'VectorStoreQueryResult', 'BaseReader']]\n",
      "[[0.20706743001937866, 0.20858651399612427, 0.21218907833099365]]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"I am using unstructured loader to load documents in my chroma vector store. Now before i run vectorstorefromdocuemnts to load them in to my db, can i get the nodes in a variable? I want them in a variable so that i can setup a recursive retriever for questions+ summaries\n",
    "dir_reader = SimpleDirectoryReader('./data/download', file_extractor={ \".html\": UnstructuredReader(),\n",
    "})\n",
    "documents = dir_reader.load_data() \"\"\"\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['ids'])\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PrevNextNodePostprocessor', 'AutoPrevNextNodePostprocessor', 'FixedRecencyPostprocessor']]\n",
      "[[0.16977083683013916, 0.1976819634437561, 0.2234247326850891]]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Find relevant class that contains context to answer the question:\n",
    "Question: Hi, I am tryin to use  PrevNextNodePostprocessor to retrieve more nodes from the same document but I get  raise ValueError(f\"doc_id {doc_id} not found.\")\n",
    "ValueError: doc_id e4e59a11-a8d6-4141-b775-9b60d8af1788 not found.\n",
    " whenever I use this option.\n",
    "This is the code I implemented to use this feature:\n",
    "    node_postprocessors =[ PrevNextNodePostprocessor(docstore=storage_context.docstore,num_nodes=2,mode=\"both\")]\n",
    "\n",
    "First I thought that maybe some retreived nodes are the first or the last chunk of document and there is no next/prev node related to them but it seems this is not the main problem. \n",
    "Any I idea what am I doing wrong?\"\"\"\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['ids'])\n",
    "print(explanations.search_all(query, type=\"class\", top_k=3)['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[\"('FalkorDBGraphStore', 'client', {'type': 'class-method'})\", \"('SimpleGraphStore', 'client', {'type': 'class-method'})\", \"('FalkorDBGraphStore', 'query', {'type': 'class-method'})\"]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[[0.17140060663223267, 0.1740317940711975, 0.1760176420211792]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"connect to a graphdb\"\n",
    "metadata = {\n",
    "    \"type\": \"class-method\"\n",
    "}\n",
    "display(Markdown(f\"{triplets.search_with_metadata(query, metadata=metadata, top_k=3)['ids']}\"))\n",
    "display(Markdown(f\"{triplets.search_all(query, top_k=3)['distances']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[\"('ChatMemoryBuffer', '_token_count_for_message_count', {'type': 'class-method'})\", \"('ChatMemoryBuffer', 'validate_memory', {'type': 'class-method'})\", \"('SimpleChatEngine', 'chat_history', {'type': 'class-method'})\"]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[[0.1764432191848755, 0.19341790676116943, 0.19564461708068848]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"When using memory = ChatMemoryBuffer.from_defaults(token_limit=YOUR_LIMIT) to remove old history and limit token usage, is there a way to detect when the memory limit is hit and print a notification every time it happens?\"\n",
    "metadata = {\n",
    "    \"type\": \"class-method\"\n",
    "}\n",
    "display(Markdown(f\"{triplets.search_with_metadata(query, metadata=metadata, top_k=3)['ids']}\"))\n",
    "display(Markdown(f\"{triplets.search_all(query, top_k=3)['distances']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[\"('BaseOpenAIAgent', 'chat', {'type': 'class-method'})\", \"('OpenAIAgent', '__init__', {'type': 'class-method'})\", \"('BaseOpenAIAgent', '__init__', {'type': 'class-method'})\"]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[[0.12255251407623291, 0.12497341632843018, 0.1259850263595581]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What is an OpenAIAgent\"\n",
    "metadata = {\n",
    "    \"type\": \"class-method\"\n",
    "}\n",
    "display(Markdown(f\"{triplets.search_with_metadata(query, metadata=metadata, top_k=3)['ids']}\"))\n",
    "display(Markdown(f\"{triplets.search_all(query, top_k=3)['distances']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SEARCH_FOR_CLASS = \"\"\"Find relevant class that contains context to answer the question:\n",
    "Question: {query}\"\"\"\n",
    "# VECTOR_SEARCH_FOR_CLASS = \"\"\"Match the python class that contains context to answer the question:\n",
    "# Question: {query}\"\"\"\n",
    "\n",
    "DISTANCE_THRESHOLD = 0.20\n",
    "DIFFERENCE_THRESHOLD = 0.015\n",
    "\n",
    "def get_initial_information(query: str, graph, explanations, triplets) -> str:\n",
    "    \"\"\"takes in a query and try to logically reason for relevant context\"\"\"\n",
    "    relevant_class = get_relevant_class(query, explanations)\n",
    "    if relevant_class is not None:\n",
    "        # get the code for the class element\n",
    "        element = graph.G.nodes[relevant_class]\n",
    "        # code = graph.get_code(element, element['elementname'])\n",
    "        edges = graph.get_edges_by_type(element)\n",
    "        _string = \"The following is some context for the class {class_name}.\\n\"\n",
    "        _string += \"The class {class_name} has the following properties:\\n\\n\"\n",
    "        for edge in edges.edges:\n",
    "            _string += f\"{edge.start_node} : {edge.metadata['type']} : {edge.end_node}\\n\"\n",
    "        return _string.format(class_name=relevant_class)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_relevant_class(query: str, explanations) -> str:\n",
    "    \"\"\"takes in a query and try to logically reason for relevant class\"\"\"\n",
    "    _prompt = VECTOR_SEARCH_FOR_CLASS.format(query=query)\n",
    "    results = explanations.search_all(_prompt, type=\"class\", top_k=3)\n",
    "    names = results['ids'][0]\n",
    "    distances = results['distances'][0]\n",
    "    zipped = zip(names, distances)\n",
    "    # filter out the ones that are too far away\n",
    "    filtered = list(filter(lambda x: x[1] < DISTANCE_THRESHOLD, zipped))\n",
    "    # if the len is 0, return None\n",
    "    if len(filtered) == 0:\n",
    "        return None\n",
    "    elif len(filtered) == 1:\n",
    "        return filtered[0][0]\n",
    "    elif len(filtered) > 1:\n",
    "        # if the difference between the first and second is too small, return None\n",
    "        if filtered[1][1] - filtered[0][1] < DIFFERENCE_THRESHOLD:\n",
    "            return None\n",
    "        else:\n",
    "            return filtered[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OpenAIAgent', 'ActionReasoningStep', 'ReActAgentWorker']\n",
      "[0.18082481622695923, 0.20768463611602783, 0.20960694551467896]\n",
      "[('OpenAIAgent', 0.18082481622695923)]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Does OpenAIAgent have a method called get_action?\"\"\"\n",
    "r = get_initial_information(query, graph, explanations, triplets)\n",
    "# export r to a 01.txt file\n",
    "if r is not None:\n",
    "    with open(\"tests/v0.0.3/01.txt\", \"w\") as f:\n",
    "        f.write(r)\n",
    "else:\n",
    "    print(\"No relevant class found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can see with the help of code above, we can generate relevant initial context for certain queries, it doesn't really work for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
